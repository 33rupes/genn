
//----------------------------------------------------------------------------
/*! \page UserGuide Suggestions for users

GeNN generates code according to the network model defined by the user, but lets users use generated code the way they want. Here we explain how to setup GeNN and how to use generated functions. We recommend users to take a look at the \ref Examples, and to follow the tutorials \ref Tutorial1 and \ref Tutorial2.

\section CreateAndSimulate Creating and simulating a network model 

The user is first expected to create an object of class NNmodel by creating the function modelDefinition() which includes calls to following methods in correct order:

- initGeNN(); 
- NNmodel::setName();  

Then add neuron populations by:

- NNmodel::addNeuronPopulation();

for each neuron population. Add synapse populations by:

- NNmodel::addSynapsePopulation();

for each synapse population.

Other optional functions are explained in NNmodel class reference. At the end the function should look like this:
 
\code
void modelDefinition(NNModel &model) {
  initGeNN();
  model.setName("YourModelName");
  model.addNeuronPopulation(...);
  ...
  model.addSynapsePopulation(...);
  ...
}
\endcode

modelSpec.h and modelSpec.cc should be included in the file where this function is defined.

This function will be called by generateALL.cc to create corresponding CPU and GPU simulation codes under the <YourModelName>_CODE directory.

These functions can then be used in a .cu file which runs the simulation. This file should include <YourModelName>_CODE/runner.cc. Generated code differ from one model to the other, but core functions are the same and they should be called in correct order. First, following variables should be defined and initialized:

- NNmodel model // initialized by calling modelDefinition(model)
- Array containing current input (if any)

Following are declared by GeNN but should be initialized by the user:
- Poisson neuron offset and rates (if any)
- Connectivity matrices (if sparse) 
- Neuron and synapse variables (if not initialising to same value)

Core functions generated by GeNN to be included in the user code include:

- allocateMem()
- deviceMemAllocate()
- allocate<synapse name>(unsigned int SparseProjection.connN) //for sparse connectivity only
- initialize()
- initializeAllSparseArrays()
- convertProbabilityToRandomNumberThreshold()

- copyStateToDevice() 
- push<neuron or synapse name>toDevice()
- pull<neuron or synapse name>fromDevice()

- copyStateFromDevice() 

- copySpikeNFromDevice()
- copySpikesFromDevice()

- stepTimeCPU() //arguments depend on model
- stepTimeGPU() //arguments depend on model

- freeMem()
- freeDeviceMem()

Copying elements from GPU to host memory is very costly in terms of performance and should only be done when needed.
 
\section floatPrecision Floating point precision

Double precision floating point numbers are supported by devices with compute capability 1.3 or higher. If you have an older GPU, you need to use single precision floating point in your models and simulation. 

GPUs are designed to work better with single precision while double precision is the standard for CPUs. This difference should be kept in mind while compaing performance.

While setting up the network for GeNN, double precision floating point numbers are used as this part is done on the CPU. For the simulation, GeNN lets users choose between single or double precision. Overall, new variables in the generated code are defined with the precision specified by NNmodel::setPrecision(unsigned int), providing FLOAT or DOUBLE as argument. FLOAT is the default value. Keyword \c scalar can be used in the user-defined model codes for an interchangeable precision. This keyword is detected at code generation and substituted with "float" or "double" according to the precision set by NNmodel::setPrecision(unsigned int).
 
There may be ambiguities in arithmetic operations using explicit numbers. Standard C compilers presume that any number defined as "X" is an integer and any number defined as "X.Y" is a double. Make sure to use same precision in your operations in order to avoid performance loss.

\section ListOfVariables Working with variables in GeNN

\subsection modelVars Model variables
User-defined model variables originate from core units such as neuronModel, weightUpdateModel or postSynModel object. The name of the variable is defined when the model type is introduced, i.e. with a statement such as
\code
neuronModel model;
model.varNames.push_back(String"x"));
model.varTypes.push_back(String("double"));
...
int myModel= nModels.size();
nModels.push_back(model);
\endcode
This declares that whenever the defined model type of cardinal number `myModel` is used, there will be a variable of core name `x`. varType can be of \c scalar type (see \ref floatPrecision). The full GeNN name of this variable is obtained by directly concatenating the core name with the name of the neuron population in which the model type has been used, i.e. after a definition
\code
networkModel.addNeuronPopulation("EN", n, myModel, ...);
\endcode
there will be a variable `xEN` of type `double*` available in the global namespace of the simulation program. GeNN will pre-allocated this C array to the correct size of elements corresponding to the size of the neuron population, `n` in the example above. GeNN will also free these variables when the provided function `freeMem()` is called. Users can otherwise manipulate these variable arrays as they wish.
For convenience, GeNN provides functions `pullXXfromDevice()` and `pushXXtoDevice()` to copy the variables associated to a neuron population `XX` from the device into host memory and vice versa. E.g.
\code
pullENfromDevice();
\endcode
would copy the C array xEN from device memory into host memory (and any other variables that the neuron type of the population EN may have). 

The user can also directly use CUDA memory copy commands independent of the provided convenience function. The relevant device pointers for all variables that exist in host memory have the same name prefixed with `d_`. For example, the copy command that would be contained in `pullENfromDevice()` might look like
\code
unsigned int size;	
size = sizeof(double) * nEN;
cudaMemcpy(xEN, d_xEN, size, cudaMemcpyDeviceToHost);
\endcode
where `n` is an integer containing the population size of the EN neuron population.

The same convention as for neuron variables applies for the variables of synapse groups, both for those originating from weightupdate models and from post-synaptic models, e.g. the variables in type `NSYNAPSE` contain the variable `g` of type float. Then, after
\code
networkModel.addSynapsePopulation("ENIN", NSYNAPSE, ...);
\endcode
there will be a global variable of type `float*` with the name `gENIN` that is pre-allocated to the right size. There will also be a matching device pointer with the name `d_gENIN`. 
\note
The content of `gENIN` needs to be interpreted differently for DENSE connectivity and sparse matrix based SPARSE connectivity representations. For DENSE connectivity `gENIN` would contain "n_pre" times "n_post" elements, ordered along the pre-synaptic neuronsas the major dimension, i.e. the value of `gENIN` for the ith pre-synaptic neuron and the jth post-synaptic neuron would be `gENIN[i*n_post+j]`. The arrangement of values in the SPARSE representation is explained in section \ref subsect32

\subsection predefinedVars Built-in Variables in GeNN

With GeNN 2.0, there are no more explicitly hard-coded synapse and neuron variables. Users are free to call the variable of their models as they want. However, there are some reserved variables that are used for intermediary calculations and communication between different parts of the generated code. They can be used in the user defined code but no other variables should be defined with these names.

- \c DT : Time step (in ms) for simulation, supposedly calling neuron and synapse updates to be called for each step.
Neuron integration can be done in multiple steps for numerical reasons inside the neuron model (see Traub-Miles and Izhikevich neuron model variations in \ref sectNeuronModels).

- \c addtoinSyn : This variable is used by weightUpdateModel for updating synaptic input. The way it is modified is defined in weightUpdateModel.simCode or weightUpdateModel.simCodeEvnt,
 therefore if a user defines her own model she should update this variable to contain the input to the post-synaptic model.   

- \c updatelinsyn : At the end of the synaptic update by \c addtoinSyn, final values are copied back to the d_inSyn<synapsePopulation> variables which will be used in the next step of the neuron update to provide the input to the postsynaptic neurons.

- \c inSyn : This is an intermediary synapse variable which contains everything is transferred from a presynaptic neuron (by using \c addtoinSyn variable) to a postsynaptic neuron. 

- \c Isyn : This is a local variable which defines the (summed) input current to a neuron. It is typically the sum of any explicit current input 
and all synaptic inputs. The way its value is calculated during the update of the postsynaptic neuron is defined by the code provided in the postSynModel. For example, the standard `EXPDECAY` postsynaptic model defines
ps.postSyntoCurrent= String("$(inSyn)*($(E)-$(V))");
\endcode
which implements a conductance based synapse in which the postsynaptic current is given by \f$I_{\rm syn}= g*s*(V_{\rm rev}-V_{\rm post})\f$. 
\note
The `addtoinSyn` variables from all incoming synapses are automatically summed and added to the current value of `inSyn`.

The value resulting from the `postSyntoCurrent` code is assigned to `Isyn` and  can then be used in neuron simCode like so:
\code
$(V)+= (-$(V)+$(Isyn))*DT 
\endcode 

- \c sT : As a neuron variable, this is the last spike time in a neuron and is automatically generated for pre and postsynaptic neuron groups of a synapse group i that follows a spike based learning rule (indicated by usesPostLearning[i]= TRUE for the ith synapse population).

In addition to these variables, neuron variables can be referred to in the synapse models by calling $(<neuronVarName>_pre) for the presynaptic neuron population, and $(<neuronVarName>_post) for the postsynaptic population. For example, \$(sT_pre), \$(sT_post), \$(V_pre), etc.
 
\section Debugging Debugging suggestions
In Linux, users can use cuda-gdb to debug GPU. Example projects in userproject and lib/bin/buildmodel.sh come with a flag to enable debugging.
If you are using a project with debugging, the code will be compiled with -g -G flags. In CPU mode the executable will be run in gdb,
and in GPU mode it will be run in cuda-gdb in tui mode. 
<br />

-----
\link sect_postsyn Previous\endlink | \link ListOfVariables Top\endlink | \link  Credits Next\endlink

*/
  
